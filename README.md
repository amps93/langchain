LangChain

ìœ„í‚¤ë…ìŠ¤ ë° ìœ íŠœë¸Œ ë“± ì›¹ì—ì„œ ê³µê°œëœ ë­ì²´ì¸ í•™ìŠµì„ ì‹¤ìŠµí•œ repo

1. [&lt;ë­ì²´ì¸LangChain ë…¸íŠ¸&gt; - LangChain í•œêµ­ì–´ íŠœí† ë¦¬ì–¼ğŸ‡°ğŸ‡· - WikiDocs](https://wikidocs.net/book/14314) - langchain_note

2. [ë­ì²´ì¸(LangChain) ì…ë¬¸ë¶€í„° ì‘ìš©ê¹Œì§€ - WikiDocs](https://wikidocs.net/book/14473) - langchain_bottom_top

3. [ëª¨ë‘ì˜AI - YouTube](https://www.youtube.com/@AI-km1yn/videos) - almost_langchain

# LangChain
## 1. ë­ì²´ì¸ ê¸°ë³¸ íë¦„
í”„ë¡¬í”„íŠ¸ -> ëª¨ë¸ -> ì•„ì›ƒí’‹ íŒŒì„œ -> invoke

```
prompt = PromptTemplate.from_template("You are an expert in astronomy. Answer the question. <Question>: {input}")
llm = ChatOpenAI(model="gpt-4o-mini")
output_parser = StrOutputParser()

chain = prompt | llm | output_parser

print(chain.invoke({"input": "ì§€êµ¬ì˜ ìì „ ì£¼ê¸°ëŠ”?"}))
```

## 2. í”„ë¡¬í”„íŠ¸
* PromptTemplate: ë‹¨ìˆœí•œ í”„ë¡¬í”„íŠ¸ ìƒì„±ì— ì í•©, ë‹¨ìˆœí•œ í…œí”Œë¦¿
```
prompt_template = PromptTemplate.from_template("ì•ˆë…•í•˜ì„¸ìš”, ì œ ì´ë¦„ì€ {name}ì´ê³ , ë‚˜ì´ëŠ” {age}ì‚´ì…ë‹ˆë‹¤.")
```
* ChatPromptTemplate: ëŒ€í™”í˜• í”„ë¡¬í”„íŠ¸ë¥¼ ìœ„í•œ í…œí”Œë¦¿ ìƒì„±ì— ì í•©, ë³µì¡í•œ í…œí”Œë¦¿
``` 
chat_prompt = ChatPromptTemplate.from_messages([
    ("system", "ì´ ì‹œìŠ¤í…œì€ ì²œë¬¸í•™ ì§ˆë¬¸ì— ë‹µë³€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."),
    ("user", "{user_input}"),
])
```

## 3. ëª¨ë¸
* LLM: ì¼ë°˜ í…ìŠ¤íŠ¸ ì…ë ¥ì„ ë°›ê³  ì´ì— ëŒ€í•œ ì‘ë‹µì„ ìƒì„±. ê´‘ë²”ìœ„í•œ ì–¸ì–´ ì´í•´ ë° í…ìŠ¤íŠ¸ ìƒì„±
```
llm = OpenAI()
result = llm("Explain what LangChain is.")
print(result)
```

* Chat Model: ë©”ì‹œì§€ì˜ ë¦¬ìŠ¤íŠ¸ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ê³ , í•˜ë‚˜ì˜ ë©”ì‹œì§€ë¥¼ ë°˜í™˜. ì±—ë´‡

```
chat = ChatOpenAI()
messages = [
    SystemMessage(content="You are a helpful assistant."),
    HumanMessage(content="What is LangChain?")
]
response = chat(messages)
print(response.content)
```
* íŒŒë¼ë¯¸í„° 
  * temperature: ìƒì„±ë˜ëŠ” í…ìŠ¤íŠ¸ì˜ ì°½ì˜ì„±ì„ ì¡°ì ˆ. ê°’ì´ ì‘ìœ¼ë©´ ì¼ê´€ëœ ì¶œë ¥, ë†’ìœ¼ë©´ ë‹¤ì–‘í•˜ê³  ì˜ˆì¸¡ ì–´ë ¤ìš´ ì¶œë ¥. 
  * max_tokens: ìƒì„±í•  í…ìŠ¤íŠ¸ì˜ ìµœëŒ€ í† í° ìˆ˜ë¥¼ ì œí•œ 
  * top_p: ì¶œë ¥ì˜ í™•ë¥  ë¶„í¬ì—ì„œ ìƒìœ„ P% í† í°ë§Œì„ ê³ ë ¤. ì¶œë ¥ì˜ ë‹¤ì–‘ì„± ì¡°ì •ì— ë„ì›€ì´ ë¨ 
  * frequency_penalty: ë™ì¼í•œ ì–´íœ˜ê°€ ë°˜ë³µë˜ëŠ” ê²ƒì„ ì¤„ì´ê¸° ìœ„í•œ íŒ¨ë„í‹°. í´ìˆ˜ë¡ ë‹¨ì–´ë‚˜ êµ¬ì ˆì˜ ì¬ë“±ì¥ í™•ë¥  ê°ì†Œ. (0~1)
  * presence_penalty: ìƒˆë¡œìš´ ì£¼ì œë‚˜ ì–´íœ˜ê°€ ë” ìì£¼ ë‚˜ì˜¤ë„ë¡ ìœ ë„í•˜ëŠ” íŒ¨ë„í‹°. í´ìˆ˜ë¡ ìƒˆë¡œìš´ ë‹¨ì–´ ë“±ì¥ í™•ë¥  ì¦ê°€. (0~1)
  * Stop Sequences (ì •ì§€ ì‹œí€€ìŠ¤): íŠ¹ì • ë‹¨ì–´ë‚˜ êµ¬ì ˆì´ ë“±ì¥í•  ê²½ìš° ìƒì„±ì„ ë©ˆì¶”ë„ë¡ ì„¤ì •. ì¶œë ¥ì„ íŠ¹ì • í¬ì¸íŠ¸ì—ì„œ ì¢…ë£Œí•˜ê³ ì í•  ë•Œ ì‚¬ìš©.
  * ```
    model = ChatOpenAI(model="gpt-4o-mini", temperature=0, max_tokens=100)
    ```
* bind: chain ë‹¨ê³„ì—ì„œ ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„°ë¥¼ ì¶”ê°€ë¡œ ì„¤ì •í•  ìˆ˜ ìˆìŒ
  * ```
    model = ChatOpenAI(model="gpt-4o-mini", max_tokens=100)
    chain = prompt | model.bind(max_tokens=10)
    ```

## 4. ì¶œë ¥ íŒŒì„œ
ëª¨ë¸ì˜ ì¶œë ¥ì„ ì²˜ë¦¬í•˜ê³ , ê·¸ ê²°ê³¼ë¥¼ ì›í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ë³€í™˜. csv, json ë“± ë‹¤ì–‘í•œ ë°©ì‹ìœ¼ë¡œ ì¶œë ¥ ê°€ëŠ¥
```
output_parser = StrOutputParser()  # JsonOutputParser, CommaSeparatedListOutputParser

chain = prompt | llm | output_parser
```

# RAG(Retrieval-Augmented Generation)
ì£¼ì–´ì§„ ì§ˆë¬¸ì— ëŒ€í•´ ì–¸ì–´ ëª¨ë¸(LLM)ê³¼ ê²€ìƒ‰ ì‹œìŠ¤í…œì„ ê²°í•©í•˜ì—¬ ë” ë‚˜ì€ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë°©ì‹. ê²€ìƒ‰ê³¼ ìƒì„± ë‘ ë‹¨ê³„ë¡œ êµ¬ì„±ë¨
1. ê²€ìƒ‰ (Retrieval)
   1. ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì§ˆë¬¸ì— ë§ì¶° ì™¸ë¶€ ë°ì´í„° ì†ŒìŠ¤(ë°ì´í„°ë² ì´ìŠ¤, ë¬¸ì„œ ì €ì¥ì†Œ, API ë“±)ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰ 
   2. ì´ ë‹¨ê³„ì—ì„œ ë¬¸ì„œë‚˜ í…ìŠ¤íŠ¸ ì¡°ê°ë“¤ì´ ê°€ì ¸ì™€ì§€ë©°, ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„± 
   3. LangChainì—ì„œ ì´ ì‘ì—…ì€ Vector Storeë¥¼ ì‚¬ìš©í•˜ì—¬ ìˆ˜í–‰. ì—¬ê¸°ì„œ ë²¡í„°í™”ëœ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ëŠ” ê²ƒì´ ì¼ë°˜ì 
2. ìƒì„± (Generation)
   1. ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì–¸ì–´ ëª¨ë¸(LLM)ì´ ìµœì¢… ì‘ë‹µì„ ìƒì„± 
   2. ë‹¨ìˆœíˆ ëª¨ë¸ì˜ ë‚´ì¬ëœ ì§€ì‹ì„ ì‚¬ìš©í•˜ì—¬ ìƒì„±í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ê²€ìƒ‰ëœ ìë£Œë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ì—¬ ë‹µë³€ì˜ ì •í™•ì„±ì„ ë†’ì„

## 1. Document Loader: ë‹¤ì–‘í•œ ì†ŒìŠ¤ì˜ ë¬¸ì„œë¥¼ ë¶ˆëŸ¬ì˜¤ê³  ì²˜ë¦¬
ì›¹, í…ìŠ¤íŠ¸, csv, pdf ë“± ë‹¤ì–‘í•œ ë¬¸ì„œ ë¡œë“œ ê°€ëŠ¥
1. ì›¹ ë¬¸ì„œ ë¡œë“œ
```
import bs4
from langchain_community.document_loaders import WebBaseLoader

url1 = "https://blog.langchain.dev/week-of-1-22-24-langchain-release-notes/"

loader = WebBaseLoader(
    web_paths=(url1, url2),
    bs_kwargs=dict(
        parse_only=bs4.SoupStrainer(
            class_=("article-header", "article-content")
        )
    ),
)
docs = loader.load()
```
2. csv ë¡œë“œ
```
loader = CSVLoader(file_path='á„’á…¡á†«á„€á…®á†¨á„Œá…®á„á…¢á†¨á„€á…³á†·á„‹á…²á†¼á„€á…©á†¼á„‰á…¡_á„Œá…®á„á…¢á†¨á„€á…³á†·á„‹á…²á†¼á„€á…ªá†«á„…á…§á†«_á„Œá…µá„‰á…®_20160101.csv', encoding='cp949')
data = loader.load()
```

### Text splitter
ê¸´ ë¬¸ì„œë¥¼ ì‘ì€ ë‹¨ìœ„ì¸ ì²­í¬(chunk)ë¡œ ë‚˜ëˆ”. CharacterTextSplitter, RecursiveCharacterTextSplitter ë“±ì´ ìˆìŒ
```
text_splitter = CharacterTextSplitter(
    separator = '',
    chunk_size = 500,
    chunk_overlap  = 100,
    length_function = len,
)
texts = text_splitter.split_text(data[0].page_content)
```
### í† í° ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ í…ìŠ¤íŠ¸ ë¶„í• 
ëª¨ë¸ì´ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” í† í° ìˆ˜ì—ëŠ” í•œê³„ê°€ ìˆìŒ. ì…ë ¥ ë°ì´í„°ë¥¼ ëª¨ë¸ì˜ ì œí•œì„ ì´ˆê³¼í•˜ì§€ ì•Šë„ë¡ ì ì ˆíˆ ë¶„í• í•˜ëŠ” ê²ƒì´ ì¤‘ìš”.
tiktoken ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©í•´ í† í¬ë‚˜ì´ì € ê¸°ì¤€ìœ¼ë¡œ ë¶„í• 

ê¸€ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ë¶„í• í•  ë•Œ tiktoken í† í¬ë‚˜ì´ì €ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê¸€ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ì—¬ ë¶„í• 
```
text_splitter = CharacterTextSplitter.from_tiktoken_encoder(
    chunk_size=600,
    chunk_overlap=200,
    encoding_name='cl100k_base'
)

docs = text_splitter.split_documents(data)
```

## Embedding
í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ìˆ«ìë¡œ ì´ë£¨ì–´ì§„ ë²¡í„°ë¡œ ë³€í™˜í•˜ì—¬ ìˆ˜ì¹˜ì  í‘œí˜„ìœ¼ë¡œ ë§Œë“œëŠ” ê³¼ì •. OpenAI, HuggingFace, Google ì—ì„œ ì„ë² ë”© ëª¨ë¸ì„ ì œê³µ
```
embeddings_model = OpenAIEmbeddings()
embeddings = embeddings_model.embed_documents(
    [
        'ì•ˆë…•í•˜ì„¸ìš”!',
        'ì–´! ì˜¤ëœë§Œì´ì—ìš”',
        'ì´ë¦„ì´ ì–´ë–»ê²Œ ë˜ì„¸ìš”?',
        'ë‚ ì”¨ê°€ ì¶”ì›Œìš”',
        'Hello LLM!'
    ]
)
```

## Vector Store
ì„ë² ë”©ëœ ë²¡í„°ë“¤ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì €ì¥í•˜ê³  ê²€ìƒ‰í•  ìˆ˜ ìˆëŠ” ì‹œìŠ¤í…œ í˜¹ì€ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì˜ë¯¸. Chroma, FAISS ë“±
```
embeddings_model = HuggingFaceEmbeddings(
    model_name='jhgan/ko-sbert-nli',
    model_kwargs={'device':'cpu'},
    encode_kwargs={'normalize_embeddings':True},
)


vectorstore = FAISS.from_documents(documents,
                                   embedding = embeddings_model,
                                   distance_strategy = DistanceStrategy.COSINE
                                   )
```

## Retriever
ë²¡í„° ì €ì¥ì†Œì—ì„œ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ëŠ” ë„êµ¬. ë‹¨ì¼ Retriver, Multi Query Retriver, Contextual compression ë“±
```
# ê²€ìƒ‰ ì¿¼ë¦¬
query = 'ì¹´ì¹´ì˜¤ë±…í¬ì˜ í™˜ê²½ëª©í‘œì™€ ì„¸ë¶€ì¶”ì§„ë‚´ìš©ì„ ì•Œë ¤ì¤˜'

# ê°€ì¥ ìœ ì‚¬ë„ê°€ ë†’ì€ ë¬¸ì¥ì„ í•˜ë‚˜ë§Œ ì¶”ì¶œ
retriever = vectorstore.as_retriever(search_kwargs={'k': 1})

docs = retriever.invoke(query)
docs[0]
```